{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "# 0:machine 1:human\n",
    "import json\n",
    "import random\n",
    "domain1 = []\n",
    "with open('../data/domain1_train.json', 'r') as json_file:\n",
    "    for line in json_file:\n",
    "        try:\n",
    "            json_data = json.loads(line)\n",
    "            domain1.append(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "domain2 = []\n",
    "with open('../data/domain2_train.json', 'r') as json_file:\n",
    "    for line in json_file:\n",
    "        try:\n",
    "            json_data = json.loads(line)\n",
    "            domain2.append(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the second approach of lgb model, which is first learn the knowledge from domain 1 and learn and fine tune the model on domain 2, which does not have a good results as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_0 = [item for item in domain2 if item['label'] == 0]\n",
    "data_label_1 = [item for item in domain2 if item['label'] == 1]\n",
    "random.seed(42)  \n",
    "chosen_domain_2 = random.sample(data_label_0, 2150) \n",
    "final_domain_2 = data_label_1 + chosen_domain_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain = domain1 + domain2\n",
    "old_text = []\n",
    "labels = []\n",
    "for i in range(len(all_domain)):\n",
    "    old_text.append(all_domain[i]['text'])\n",
    "    labels.append(all_domain[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = old_text\n",
    "unique_integers = set()\n",
    "for integer_list in data:\n",
    "    unique_integers.update(integer_list)\n",
    "vocabulary = sorted(list(unique_integers))\n",
    "bow_data = []\n",
    "for integer_list in data:\n",
    "    bow_vector = [integer_list.count(word) for word in vocabulary]\n",
    "    bow_data.append(bow_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_data_1 = bow_data[0:19500] #domain 1 bow\n",
    "bow_data_2 = bow_data[19500:]\n",
    "labels_1 = labels[0:19500] # domain 1 label\n",
    "labels_2 = labels[19500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "X = bow_data_1\n",
    "y = labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7793, number of negative: 7807\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8459\n",
      "[LightGBM] [Info] Number of data points in the train set: 15600, number of used features: 2499\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499551 -> initscore=-0.001795\n",
      "[LightGBM] [Info] Start training from score -0.001795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.172466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x307b98dd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params in model\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'early_stopping_rounds': 100\n",
    "}\n",
    "\n",
    "\n",
    "# train model and saved the model based on domain1 \n",
    "num_round = 100\n",
    "bst_domain1  = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "bst_domain1.save_model(\"domain1_model.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text_2 = []\n",
    "labels_2 = []\n",
    "for i in range(len(domain2)):\n",
    "    old_text_2.append(domain2[i]['text'])\n",
    "    labels_2.append(domain2[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the domain 1 model, learn and fine tune the model based on domain 2\n",
    "bst_domain1 = lgb.Booster(model_file=\"domain1_model.txt\")\n",
    "X_2 = bow_data_2\n",
    "y_2 = labels_2\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the full data from domain2 but added the class weight for each machine and human generated text\n",
    "class_weights_domain2 = np.array([1.0, 5.0]) \n",
    "X_train_2 = np.array(X_train_2)\n",
    "X_test_2 = np.array(X_test_2)\n",
    "train_data_2 = lgb.Dataset(X_train_2, label=y_train_2,weight=class_weights_domain2[y_train_2])\n",
    "test_data_2 = lgb.Dataset(X_test_2, label=y_test_2, reference=train_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Info] Number of positive: 1714, number of negative: 10206\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19971\n",
      "[LightGBM] [Info] Number of data points in the train set: 11920, number of used features: 4421\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.370469\n"
     ]
    }
   ],
   "source": [
    "# Domain2 (Fine-tuning）\n",
    "num_round_domain2 = 50 \n",
    "params_domain2 = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'early_stopping_rounds': 100\n",
    "}\n",
    "# train the final model \n",
    "bst_domain2 = lgb.train(params_domain2, train_data_2, num_round_domain2, valid_sets=[test_data_2], init_model=bst_domain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on the test dataset\n",
    "test = []\n",
    "with open('../data/test_set.json', 'r') as json_file:\n",
    "    for line in json_file:\n",
    "        try:\n",
    "            json_data = json.loads(line)\n",
    "            test.append(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "# taking all the data out to get the predictions\n",
    "# 需要做测试的数据有1000组\n",
    "X_train_final = []\n",
    "for i in range(len(test)):\n",
    "    X_train_final.append(test[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer the data into bow formatting\n",
    "data = old_text\n",
    "unique_integers = set()\n",
    "for integer_list in data:\n",
    "    unique_integers.update(integer_list)\n",
    "\n",
    "vocabulary = sorted(list(unique_integers))\n",
    "\n",
    "\n",
    "bow_data_final = []\n",
    "for integer_list in X_train_final: #\n",
    "    bow_vector = [integer_list.count(word) for word in vocabulary]\n",
    "    bow_data_final.append(bow_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer into np.array formatt\n",
    "bow_data_final = np.array(bow_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions\n",
    "y_pred_final = bst_domain2.predict(bow_data_final, num_iteration=bst_domain2.best_iteration,predict_disable_shape_check=True)\n",
    "y_pred_binary_final = (y_pred_final > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "for i in range(0,1000):\n",
    "    id.append(i)\n",
    "\n",
    "answer = []\n",
    "for i in range(0,1000):\n",
    "    answer.append((id[i],y_pred_binary_final[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to ../Predicted_answer/lgb_bow_balance_two_model_fine_tuning.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "file_name = '../Predicted_answer/lgb_bow_balance_two_model_fine_tuning.csv'\n",
    "column_name = ['id','class']\n",
    "with open(file_name, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_name)\n",
    "    \n",
    "    for row in answer:\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "print(f'Data has been written to {file_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
